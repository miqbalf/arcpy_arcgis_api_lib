{
 "cells": [
  {
   "cell_type": "code",
   "id": "39ac9c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:15.640462Z",
     "start_time": "2025-10-15T17:44:15.634383Z"
    }
   },
   "source": [
    "# import sys\n",
    "# import warnings\n",
    "\n",
    "# # Handle ShimWarning import for different IPython versions\n",
    "# if 'IPython' in sys.modules:\n",
    "#     try:\n",
    "#         # For newer IPython versions (8.0+)\n",
    "#         from IPython.utils.shimmodule import ShimWarning\n",
    "#         warnings.filterwarnings(\"ignore\", category=ShimWarning)\n",
    "#     except ImportError:\n",
    "#         try:\n",
    "#             # For older IPython versions or alternative import paths\n",
    "#             from IPython.utils.warn import ShimWarning\n",
    "#             warnings.filterwarnings(\"ignore\", category=ShimWarning)\n",
    "#         except ImportError:\n",
    "#             # If ShimWarning is not available, just continue without filtering\n",
    "#             pass"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "acfccfd8-225e-4da2-bd58-d0156537e2f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:15.817591Z",
     "start_time": "2025-10-15T17:44:15.813893Z"
    }
   },
   "source": [
    "# !conda env list"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f9fbf43d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:16.003750Z",
     "start_time": "2025-10-15T17:44:16.000718Z"
    }
   },
   "source": [
    "# !pip install geopandas python-dotenv arcgis arcgis-mapping pandera"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4b5efab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:30.441425Z",
     "start_time": "2025-10-15T17:44:16.454433Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import csv_append\n",
    "# import arcgis\n",
    "from csv_append.main import ArcGISAPI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "arc = ArcGISAPI()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:csv_append.utils:CSV path is a URL, downloading file...\n",
      "INFO:csv_append.utils:Downloading file from url\n",
      "INFO:csv_append.utils:Successfully downloaded file to: /var/folders/rf/hnd8dn097rxbh6l24d20g27m0000gn/T/temp_download\n",
      "INFO:csv_append.main:Successfully loaded CSV with 536 rows and 15 columns\n",
      "INFO:csv_append.main:ArcGIS API initialized with lazy loading enabled\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "63f9c79a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:36.815140Z",
     "start_time": "2025-10-15T17:44:36.812321Z"
    }
   },
   "source": [
    "# webmap_item = arc.get_webmap_item_query()\n",
    "# webmap_item"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "096e5b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:37.618558Z",
     "start_time": "2025-10-15T17:44:37.615558Z"
    }
   },
   "source": [
    "# webmap_search = arc.webmap_search_data\n",
    "# webmap_search"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "3f471ca9-688c-4090-88f7-ae978addce4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:38.145857Z",
     "start_time": "2025-10-15T17:44:38.142388Z"
    }
   },
   "source": [
    "# webmap_data= webmap_item.get_data()\n",
    "# webmap_data"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "5b485123-d069-44f4-9cbe-c3ae89eb63d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:38.958097Z",
     "start_time": "2025-10-15T17:44:38.954960Z"
    }
   },
   "source": [
    "# from arcgis.layers import Service\n",
    "# webmap_data = arc.webmap_data\n",
    "# webmap_data"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "c2946f2d-4f41-4e95-9ff4-3b946b715bbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:44:39.661596Z",
     "start_time": "2025-10-15T17:44:39.658238Z"
    }
   },
   "source": [
    "# # only looks at the layers\n",
    "# for layer_group in arc.webmap_data.get('operationalLayers'):\n",
    "#     # print(layer_group)\n",
    "#     for layer in layer_group.get('layers'):\n",
    "#         # print(layer)\n",
    "#         # print(f'title: {layer.get(\"title\")}')\n",
    "#         # print(f'url: {layer.get(\"url\")}')\n",
    "#         print(layer.get('title'))"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "ddd6eb9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:12.284547Z",
     "start_time": "2025-10-15T17:44:40.463677Z"
    }
   },
   "source": [
    "#### if too long because some cache issue\n",
    "# #if there is cache\n",
    "# arc.cleanup()\n",
    "\n",
    "# example layer_name \n",
    "list_layer_to_update = ['Layer STA100 - Staff', 'Layer F1 - CO2 Emissions - backup']\n",
    "list_gdf_to_update = [arc.layer_service_to_gdf(layer_name=layer_name) for layer_name in list_layer_to_update]\n",
    "# list_gdf_to_update[0].head()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:csv_append.main:Successfully connected to portal\n",
      "INFO:csv_append.main:Webmap search successful with 2 webmaps\n",
      "INFO:csv_append.main:Successfully loaded webmap data\n",
      "INFO:csv_append.main:Found 1 layer groups\n",
      "INFO:csv_append.main:Extracted 21 layers from 1 layer groups\n",
      "INFO:csv_append.main:Built layer index with 21 layers\n",
      "INFO:csv_append.main:Successfully retrieved feature layer: Layer STA100 - Staff\n",
      "INFO:csv_append.main:Successfully converted layer 'Layer STA100 - Staff' to GeoDataFrame with 536 features\n",
      "INFO:csv_append.main:Successfully retrieved feature layer: Layer F1 - CO2 Emissions - backup\n",
      "INFO:csv_append.main:Successfully converted layer 'Layer F1 - CO2 Emissions - backup' to GeoDataFrame with 468 features\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1bd84737-c0eb-42a9-be03-87d1c1e036fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:19.048167Z",
     "start_time": "2025-10-15T17:47:19.038021Z"
    }
   },
   "source": [
    "len(arc.list_feature_layer)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "2e6facf5-5be9-4fbf-af1a-4fbe9c705c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:19.690619Z",
     "start_time": "2025-10-15T17:47:19.684393Z"
    }
   },
   "source": "len(arc.list_layers)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "1fc9f3e9-e9ab-400f-9a8b-b957f006fce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:20.387154Z",
     "start_time": "2025-10-15T17:47:20.383720Z"
    }
   },
   "source": [
    "# list_gdf_to_update[0].head()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "df238ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:21.268610Z",
     "start_time": "2025-10-15T17:47:21.265715Z"
    }
   },
   "source": [
    "# os.getenv('PUBLIC_GDRIVE')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "e78670d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:38.555175Z",
     "start_time": "2025-10-15T17:47:22.015906Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# country dataset, adapted from: https://web.archive.org/web/20231220150759/https://thematicmapping.org/downloads/TM_WORLD_BORDERS-0.3.zip\n",
    "country_gdf = arc.layer_service_to_gdf(layer_name='Other countries')\n",
    "country_gdf.head()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:csv_append.main:Successfully retrieved feature layer: Other countries\n",
      "INFO:csv_append.main:Successfully converted layer 'Other countries' to GeoDataFrame with 246 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   OBJECTID  region                 name    area   pop2005 fips iso2 iso3  un  \\\n",
       "0         1      19  Antigua and Barbuda      44     83039   AC   AG  ATG  28   \n",
       "1         2       2              Algeria  238174  32854159   AG   DZ  DZA  12   \n",
       "2         3     142           Azerbaijan    8260   8352021   AJ   AZ  AZE  31   \n",
       "3         4     150              Albania    2740   3153731   AL   AL  ALB   8   \n",
       "4         5       9       American Samoa      20     64051   AQ   AS  ASM  16   \n",
       "\n",
       "   subregion     lon     lat           Shape__Area   Shape__Length  \\\n",
       "0         29 -61.783  17.078      599360609.174805   133700.927769   \n",
       "1         15   2.632  28.163  3014479264885.230469  8343368.918563   \n",
       "2        145  47.395   40.43   147887393116.572266  3292028.755616   \n",
       "3         39  20.068  41.143    50626033492.280273  1287775.184769   \n",
       "4         61 -170.73 -14.318      246078746.763672   123260.324562   \n",
       "\n",
       "                                               SHAPE  \n",
       "0  {\"rings\": [[[-6866928.47049372, 1923670.301966...  \n",
       "1  {\"rings\": [[[329907.556109862, 4411573.9880643...  \n",
       "2  {\"rings\": [[[5018652.3369897, 4832292.096544],...  \n",
       "3  {\"rings\": [[[2163629.4454291, 5015449.24322075...  \n",
       "4  {\"rings\": [[[-18984705.4831263, -1608370.55560...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>region</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>pop2005</th>\n",
       "      <th>fips</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>un</th>\n",
       "      <th>subregion</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>44</td>\n",
       "      <td>83039</td>\n",
       "      <td>AC</td>\n",
       "      <td>AG</td>\n",
       "      <td>ATG</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>-61.783</td>\n",
       "      <td>17.078</td>\n",
       "      <td>599360609.174805</td>\n",
       "      <td>133700.927769</td>\n",
       "      <td>{\"rings\": [[[-6866928.47049372, 1923670.301966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>238174</td>\n",
       "      <td>32854159</td>\n",
       "      <td>AG</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2.632</td>\n",
       "      <td>28.163</td>\n",
       "      <td>3014479264885.230469</td>\n",
       "      <td>8343368.918563</td>\n",
       "      <td>{\"rings\": [[[329907.556109862, 4411573.9880643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>142</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>8260</td>\n",
       "      <td>8352021</td>\n",
       "      <td>AJ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>AZE</td>\n",
       "      <td>31</td>\n",
       "      <td>145</td>\n",
       "      <td>47.395</td>\n",
       "      <td>40.43</td>\n",
       "      <td>147887393116.572266</td>\n",
       "      <td>3292028.755616</td>\n",
       "      <td>{\"rings\": [[[5018652.3369897, 4832292.096544],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2740</td>\n",
       "      <td>3153731</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>20.068</td>\n",
       "      <td>41.143</td>\n",
       "      <td>50626033492.280273</td>\n",
       "      <td>1287775.184769</td>\n",
       "      <td>{\"rings\": [[[2163629.4454291, 5015449.24322075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>20</td>\n",
       "      <td>64051</td>\n",
       "      <td>AQ</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>61</td>\n",
       "      <td>-170.73</td>\n",
       "      <td>-14.318</td>\n",
       "      <td>246078746.763672</td>\n",
       "      <td>123260.324562</td>\n",
       "      <td>{\"rings\": [[[-18984705.4831263, -1608370.55560...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "6b32be8c-c7f6-4d96-a741-5c1a3aa9a000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:40.448112Z",
     "start_time": "2025-10-15T17:47:40.442253Z"
    }
   },
   "source": [
    "len(arc.list_feature_layer)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "31c4258c-5fe7-4160-906a-50a80c5f91f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:41.181994Z",
     "start_time": "2025-10-15T17:47:41.178400Z"
    }
   },
   "source": [
    "csv_gsheet_path = os.getenv('CSV_PATH')"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "187c9e8c-7755-4251-990c-9a170b70fb20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:41.828688Z",
     "start_time": "2025-10-15T17:47:41.824863Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "update_test = arc.input_df\n",
    "# update_test.head()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "98a727b7-10a7-473e-b471-a2817ab97b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:47:42.844425Z",
     "start_time": "2025-10-15T17:47:42.838655Z"
    }
   },
   "source": [
    "list_layer_to_update"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Layer STA100 - Staff', 'Layer F1 - CO2 Emissions - backup']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "d50fc149-c00f-46f8-9708-73350e259515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:50:51.823392Z",
     "start_time": "2025-10-15T17:50:51.819271Z"
    }
   },
   "source": [
    "test_layername_to_update = list_layer_to_update[0]\n",
    "test_gdb_to_update = list_gdf_to_update[0]\n",
    "# test_gdb_to_update.head()"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:50:55.771502Z",
     "start_time": "2025-10-15T17:50:52.945718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### TESTING SCHEMA\n",
    "\n",
    "# feature_layer_item = gis.content.get(\"YOUR_ITEM_ID\")\n",
    "# target_layer = arc.get_feature_layer_tile_by_name(layer_name=test_layername_to_update)[1]\n",
    "# arc.cleanup()\n",
    "# target_layer = arc.get_feature_layer_tile_by_name(layer_name=\"Other countries\")[1] # test if this works (validation)\n",
    "# target_layer\n",
    "\n",
    "layer_name_flayer = {}\n",
    "\n",
    "for i in arc.list_feature_layer:\n",
    "    # print(i.url)\n",
    "    for detail in arc.list_layers:\n",
    "        if detail.get('url') == i.url:\n",
    "            # print(f\"{detail['title']} : {i.url}\" )\n",
    "            layer_name_flayer[detail['title']] = i\n",
    "\n",
    "target_layer = layer_name_flayer[test_layername_to_update]\n",
    "# target_layer\n",
    "\n",
    "reference_layer = target_layer\n",
    "df_reference = test_gdb_to_update\n",
    "\n",
    "input_df = update_test # csv update\n",
    "wrangling = arc.csv_wrangling(layer_name=test_layername_to_update,\n",
    "                              reference_layer=reference_layer,\n",
    "                              df_reference=df_reference\n",
    "                              )\n"
   ],
   "id": "370c63990861caef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:csv_append.main:Successfully retrieved feature layer: Layer STA100 - Staff\n",
      "INFO:csv_append.main:ðŸ“˜ Field info for: Layer STA100 - Staff\n",
      "INFO:csv_append.main:------------------------------------------------------------\n",
      "INFO:csv_append.main:OBJECTID                       | esriFieldTypeOID     | alias='OBJECTID' | length=\n",
      "INFO:csv_append.main:id                             | esriFieldTypeInteger | alias='id' | length=\n",
      "INFO:csv_append.main:npo                            | esriFieldTypeString  | alias='npo' | length=2147483647\n",
      "INFO:csv_append.main:year                           | esriFieldTypeBigInteger | alias='year' | length=\n",
      "INFO:csv_append.main:metric_id                      | esriFieldTypeDouble  | alias='metric_id' | length=\n",
      "INFO:csv_append.main:metric_code                    | esriFieldTypeString  | alias='metric_code' | length=2147483647\n",
      "INFO:csv_append.main:metric_name                    | esriFieldTypeString  | alias='metric_name' | length=2147483647\n",
      "INFO:csv_append.main:metric_description             | esriFieldTypeString  | alias='metric_description' | length=2147483647\n",
      "INFO:csv_append.main:unit                           | esriFieldTypeString  | alias='unit' | length=2147483647\n",
      "INFO:csv_append.main:office                         | esriFieldTypeString  | alias='office' | length=2147483647\n",
      "INFO:csv_append.main:home_office                    | esriFieldTypeString  | alias='home_office' | length=2147483647\n",
      "INFO:csv_append.main:office_type                    | esriFieldTypeString  | alias='office_type' | length=2147483647\n",
      "INFO:csv_append.main:region                         | esriFieldTypeString  | alias='region' | length=2147483647\n",
      "INFO:csv_append.main:scenario                       | esriFieldTypeString  | alias='scenario' | length=2147483647\n",
      "INFO:csv_append.main:value_us_consolidated          | esriFieldTypeDouble  | alias='value_us_consolidated' | length=\n",
      "INFO:csv_append.main:value_us_consolidated_float    | esriFieldTypeDouble  | alias='value_us_consolidated_float' | length=\n",
      "INFO:csv_append.main:value_non_consolidated         | esriFieldTypeDouble  | alias='value_non_consolidated' | length=\n",
      "INFO:csv_append.main:value_non_consolidated_float   | esriFieldTypeDouble  | alias='value_non_consolidated_float' | length=\n",
      "INFO:csv_append.main:currency                       | esriFieldTypeString  | alias='currency' | length=2147483647\n",
      "INFO:csv_append.main:check_not_same_value_us        | esriFieldTypeInteger | alias='check_not_same_value_us' | length=\n",
      "INFO:csv_append.main:Presentation_Type              | esriFieldTypeString  | alias='Presentation_Type' | length=255\n",
      "INFO:csv_append.main:year_time                      | esriFieldTypeDate    | alias='year_time' | length=8\n",
      "INFO:csv_append.main:Shape__Area                    | esriFieldTypeDouble  | alias='Shape__Area' | length=\n",
      "INFO:csv_append.main:Shape__Length                  | esriFieldTypeDouble  | alias='Shape__Length' | length=\n",
      "INFO:csv_append.main:Found 24 fields for layer 'Layer STA100 - Staff'\n",
      "INFO:csv_append.data_val:Building validation schema from layer properties...\n",
      "INFO:csv_append.data_val:Found 24 total fields in layer\n",
      "INFO:csv_append.data_val:  -> Processing field: 'OBJECTID' (type: esriFieldTypeOID)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'OBJECTID' (type: esriFieldTypeOID)\n",
      "INFO:csv_append.data_val:  -> Processing field: 'id' (type: esriFieldTypeInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'id': Type=<class 'pandera.dtypes.Int32'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'npo' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'npo': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'year' (type: esriFieldTypeBigInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'year': Type=<class 'pandera.dtypes.Int64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_id' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_id': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_code' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_code': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_name' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_name': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_description' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_description': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'unit' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'unit': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'office' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'office': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'home_office' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'home_office': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'office_type' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'office_type': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'region' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'region': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'scenario' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'scenario': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_us_consolidated' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_us_consolidated': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_us_consolidated_float' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_us_consolidated_float': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_non_consolidated' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_non_consolidated': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_non_consolidated_float' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_non_consolidated_float': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'currency' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'currency': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'check_not_same_value_us' (type: esriFieldTypeInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'check_not_same_value_us': Type=<class 'pandera.dtypes.Int32'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Presentation_Type' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'Presentation_Type': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'year_time' (type: esriFieldTypeDate)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'year_time': Type=<class 'pandera.dtypes.Timestamp'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Shape__Area' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'Shape__Area' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Shape__Length' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'Shape__Length' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:Successfully built schema with 21 fields\n",
      "INFO:csv_append.main:Successfully updated data types. New shape: (536, 21)\n",
      "INFO:csv_append.data_val:Building validation schema from layer properties...\n",
      "INFO:csv_append.data_val:Found 24 total fields in layer\n",
      "INFO:csv_append.data_val:  -> Processing field: 'OBJECTID' (type: esriFieldTypeOID)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'OBJECTID' (type: esriFieldTypeOID)\n",
      "INFO:csv_append.data_val:  -> Processing field: 'id' (type: esriFieldTypeInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'id': Type=<class 'pandera.dtypes.Int32'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'npo' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'npo': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'year' (type: esriFieldTypeBigInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'year': Type=<class 'pandera.dtypes.Int64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_id' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_id': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_code' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_code': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_name' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_name': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_description' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_description': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'unit' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'unit': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'office' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'office': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'home_office' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'home_office': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'office_type' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'office_type': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'region' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'region': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'scenario' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'scenario': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_us_consolidated' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_us_consolidated': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_us_consolidated_float' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_us_consolidated_float': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_non_consolidated' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_non_consolidated': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_non_consolidated_float' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_non_consolidated_float': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'currency' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'currency': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'check_not_same_value_us' (type: esriFieldTypeInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'check_not_same_value_us': Type=<class 'pandera.dtypes.Int32'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Presentation_Type' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'Presentation_Type': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'year_time' (type: esriFieldTypeDate)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'year_time': Type=<class 'pandera.dtypes.Timestamp'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Shape__Area' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'Shape__Area' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Shape__Length' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'Shape__Length' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:Successfully built schema with 21 fields\n",
      "INFO:csv_append.data_val:Building validation schema from layer properties...\n",
      "INFO:csv_append.data_val:Found 24 total fields in layer\n",
      "INFO:csv_append.data_val:  -> Processing field: 'OBJECTID' (type: esriFieldTypeOID)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'OBJECTID' (type: esriFieldTypeOID)\n",
      "INFO:csv_append.data_val:  -> Processing field: 'id' (type: esriFieldTypeInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'id': Type=<class 'pandera.dtypes.Int32'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'npo' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'npo': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'year' (type: esriFieldTypeBigInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'year': Type=<class 'pandera.dtypes.Int64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_id' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_id': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_code' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_code': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_name' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_name': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'metric_description' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'metric_description': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'unit' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'unit': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'office' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'office': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'home_office' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'home_office': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'office_type' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'office_type': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'region' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'region': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'scenario' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'scenario': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_us_consolidated' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_us_consolidated': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_us_consolidated_float' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_us_consolidated_float': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_non_consolidated' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_non_consolidated': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'value_non_consolidated_float' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'value_non_consolidated_float': Type=<class 'pandera.dtypes.Float64'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'currency' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'currency': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'check_not_same_value_us' (type: esriFieldTypeInteger)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'check_not_same_value_us': Type=<class 'pandera.dtypes.Int32'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Presentation_Type' (type: esriFieldTypeString)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'Presentation_Type': Type=<class 'pandera.dtypes.String'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'year_time' (type: esriFieldTypeDate)\n",
      "INFO:csv_append.data_val:  -> Adding rule for field 'year_time': Type=<class 'pandera.dtypes.Timestamp'>, Nullable=True\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Shape__Area' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'Shape__Area' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Processing field: 'Shape__Length' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:  -> Skipping server-managed field: 'Shape__Length' (type: esriFieldTypeDouble)\n",
      "INFO:csv_append.data_val:Successfully built schema with 21 fields\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "force_update_dtype_csv\n",
      "found column npo in reference\n",
      "found column year in reference\n",
      "found column metric_id in reference\n",
      "found column metric_code in reference\n",
      "found column metric_name in reference\n",
      "found column metric_description in reference\n",
      "found column unit in reference\n",
      "found column office in reference\n",
      "found column home_office in reference\n",
      "found column office_type in reference\n",
      "found column region in reference\n",
      "found column scenario in reference\n",
      "found column value_us_consolidated in reference\n",
      "found column value_non_consolidated in reference\n",
      "found column currency in reference\n",
      "found column value_us_consolidated_float in reference\n",
      "found column id in reference\n",
      "found column year_time in reference\n",
      "found column Presentation_Type in reference\n",
      "found column value_non_consolidated_float in reference\n",
      "found column check_not_same_value_us in reference\n",
      "âœ… Valid!\n",
      "Validation result: True\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:51:11.204459Z",
     "start_time": "2025-10-15T17:51:11.200431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# {'mapped_df_esri': mapped_df_esri,\n",
    "#  'mapped_esri_df':mapped_esri_df,\n",
    "#  'comparison_old':comparison_old,\n",
    "#  'comparison_new':comparison_new,\n",
    "#  'is_valid':is_valid,\n",
    "#  'new_updated_df_revised':new_updated_df_revised,\n",
    "#  'data_processing_successful': new_updated_df_revised is not None and not new_updated_df_revised.empty\n",
    "#  }\n",
    "\n",
    "# wrangling['mapped_df_esri']\n",
    "# wrangling['mapped_esri_df']\n",
    "# wrangling['comparison_old']\n",
    "# wrangling['comparison_new']\n",
    "# wrangling['is_valid']\n",
    "# wrangling['new_updated_df_revised']\n",
    "# wrangling['data_processing_successful']"
   ],
   "id": "49db99b1a67cc189",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:51:35.730085Z",
     "start_time": "2025-10-15T17:51:35.719153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "def reload_module(string):\n",
    "    if string in sys.modules:\n",
    "        return importlib.reload(sys.modules[string])\n",
    "    else:\n",
    "        return importlib.import_module(string)\n",
    "\n",
    "\n",
    "data_val_reload = \"csv_append.data_val\"\n",
    "reload_module = reload_module(data_val_reload)\n",
    "print(f\"Module successfully loaded: {data_val_reload}\")\n"
   ],
   "id": "1c2d4aa0e844a3bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module successfully loaded: csv_append.data_val\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "########## IF FIRST CHECK DATASET WRANGLING IS DONE, WE CAN CONTINUE TO UPDATE, OTHERWISE, PLEASE ADJUST THE CSV INPUT\n",
    "### UPDATE PROCESS\n",
    "#GET THE POLYGON and POINT REFERENCE\n",
    "\n",
    "\n"
   ],
   "id": "7e292453849a647a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ed1317024c1e1c4d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
